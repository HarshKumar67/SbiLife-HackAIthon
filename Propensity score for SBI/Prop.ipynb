{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144ac935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "AUC-ROC Score: 1.0\n",
      "\n",
      "Propensity Score for New User: 0.5198\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Sample Data (Replace with your actual SBI Life dataset)\n",
    "data = {\n",
    "    'Age': [25, 40, 30, 60, 22, 45, 35, 55, 28, 50],\n",
    "    'Occupation': ['Salaried', 'Business', 'Salaried', 'Retired', 'Student', 'Business', 'Salaried', 'Retired', 'Salaried', 'Business'],\n",
    "    'Website_Activity': [10, 5, 15, 2, 8, 7, 12, 3, 9, 6],\n",
    "    'Existing_Policies': [0, 2, 1, 3, 0, 1, 2, 2, 1, 1],\n",
    "    'Income': [50000, 100000, 60000, 80000, 30000, 120000, 70000, 90000, 55000, 110000],\n",
    "    'Purchased_Policy': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]  # Target variable (1: Purchased, 0: Not Purchased)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define features and target\n",
    "features = ['Age', 'Occupation', 'Website_Activity', 'Existing_Policies', 'Income']\n",
    "target = 'Purchased_Policy'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = ['Occupation']\n",
    "numerical_features = ['Age', 'Website_Activity', 'Existing_Policies', 'Income']\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # Handle missing numerical values\n",
    "    ('scaler', StandardScaler()) # Scale numerical features\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # Handle missing categorical values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')) # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# Combine preprocessing pipelines using ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical', numerical_pipeline, numerical_features),\n",
    "    ('categorical', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create and train Logistic Regression model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42)) # Logistic Regression classifier\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model on test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1] # Probabilities for class 1 (Purchased_Policy = 1)\n",
    "\n",
    "print(\"Model Evaluation on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_test, y_prob)}\")\n",
    "\n",
    "# --- Real-time Propensity Score Prediction for New User ---\n",
    "def predict_propensity_score(user_data):\n",
    "    \"\"\"\n",
    "    Predicts the propensity score for a new user.\n",
    "\n",
    "    Args:\n",
    "        user_data (dict): Dictionary containing user features (keys should match feature names).\n",
    "\n",
    "    Returns:\n",
    "        float: Propensity score (probability of purchasing a policy).\n",
    "    \"\"\"\n",
    "    user_df = pd.DataFrame([user_data]) # Convert user data dict to DataFrame\n",
    "    propensity_score = model.predict_proba(user_df)[:, 1][0] # Predict probability and extract score\n",
    "    return propensity_score\n",
    "\n",
    "# Example of predicting propensity score for a new user\n",
    "new_user_data = {\n",
    "    'Age': 76,\n",
    "    'Occupation': 'Business',\n",
    "    'Website_Activity': 18,\n",
    "    'Existing_Policies': 4,\n",
    "    'Income': 7500\n",
    "}\n",
    "\n",
    "propensity = predict_propensity_score(new_user_data)\n",
    "print(f\"\\nPropensity Score for New User: {propensity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7aa8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Model Evaluation Results ðŸ”¹\n",
      "âœ… Accuracy Score: 0.9100\n",
      "âœ… ROC-AUC Score: 0.9398\n",
      "\n",
      "ðŸ”¹ Classification Report ðŸ”¹\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.61      0.75        44\n",
      "           1       0.90      0.99      0.95       156\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.93      0.80      0.85       200\n",
      "weighted avg       0.92      0.91      0.90       200\n",
      "\n",
      "\n",
      "âœ… Model trained and saved successfully as 'propensity_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"modified_propensity_score_dataset.csv\")\n",
    "\n",
    "# Ensure required columns exist\n",
    "required_columns = ['Age', 'Occupation', 'Website_Visits', 'Annual_Income', 'Expenses', 'Credit_Score', 'Propensity_Score']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing columns: {missing_columns}\")\n",
    "\n",
    "# Convert continuous scores to binary labels (1 = High Propensity, 0 = Low Propensity)\n",
    "df['Propensity_Label'] = (df['Propensity_Score'] >= 0.5).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "features = ['Age', 'Occupation', 'Website_Visits', 'Annual_Income', 'Expenses', 'Credit_Score']\n",
    "target = 'Propensity_Label'  # Now binary (0 or 1)\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = ['Occupation']\n",
    "numerical_features = ['Age', 'Website_Visits', 'Annual_Income', 'Expenses', 'Credit_Score']\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical', numerical_pipeline, numerical_features),\n",
    "    ('categorical', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42, stratify=df[target])\n",
    "\n",
    "# Train model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\nðŸ”¹ Model Evaluation Results ðŸ”¹\")\n",
    "print(f\"âœ… Accuracy Score: {accuracy:.4f}\")\n",
    "print(f\"âœ… ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(\"\\nðŸ”¹ Classification Report ðŸ”¹\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, \"propensity_model.pkl\")\n",
    "print(\"\\nâœ… Model trained and saved successfully as 'propensity_model.pkl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
